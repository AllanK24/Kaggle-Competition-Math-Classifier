{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9e5b15",
   "metadata": {},
   "source": [
    "## Test Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d0b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omni/Programming/Qwen2.5-Math-Classifier/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f1b0c55ebd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1aea9772c0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from utils.constants import MODEL_ID\n",
    "from utils.create_dataloaders import create_dataloaders\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "train_dataloader, val_dataloader = create_dataloaders(\n",
    "    train_dataset_path=\"/home/omni/Programming/Qwen2.5-Math-Classifier/dataset/preprocessed/train.csv\",\n",
    "    val_dataset_path=\"/home/omni/Programming/Qwen2.5-Math-Classifier/dataset/preprocessed/val.csv\",\n",
    "    batch_size=4,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9f7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 13314,    220,     23,   7379,    279,   1931,  19703,    315,    279,\n",
      "          23606,  57960,  26888,  45340,     10,     17,   1124,  26888,  45340,\n",
      "             10,     17,   1124,  26888,  45340,     10,     17,  41715,   4385,\n",
      "           2412,     10,     17,   1124,  26888,  45340,     10,     17,   1124,\n",
      "          26888,     90,     18,    856,   3417,   3417,  51185,     87,  12947,\n",
      "           2619,    525,    400,     77,      3,   9334,  19703,     13, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643],\n",
      "        [  1925,    264,    830,   2220,    710,   1273,    315,    220,     16,\n",
      "             15,     15,   3589,     11,   1449,   3405,    429,    374,    264,\n",
      "           5248,    315,    220,     19,    374,    830,     11,    323,    678,\n",
      "           3800,    525,    895,     13,   1416,    264,   5458,  15423,   1449,\n",
      "           1509,    429,    374,    264,   5248,    315,    220,     18,    895,\n",
      "            323,    678,   3800,    830,     11,   1246,   1657,    315,    279,\n",
      "            220,     16,     15,     15,   3589,    686,    387,  12440,  18577,\n",
      "             30, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643],\n",
      "        [    23,     13,     15,     15,     17,     13,    400,     22,     10,\n",
      "             19,   1124,  15940,    856,   1124,   9407,    856,     10,     16,\n",
      "             13,     20,  11520,  52591,    856,  41715,  64498,    856,  11730,\n",
      "             15,  12947, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
      "         151643, 151643],\n",
      "        [  2461,  47311,    400,     47,   2075,  11730,     16,  30529,     67,\n",
      "          37018,     90,     16,  15170,     18,     92,     87,  41715,     67,\n",
      "          37018,     90,     16,  15170,     21,     92,     87,  47822,     17,\n",
      "          31716,   1154,   6979,    400,     48,   2075,  11730,     47,   2075,\n",
      "              8,     47,   2075,  47822,     18,   5410,     47,   2075,  47822,\n",
      "             20,   5410,     47,   2075,  47822,     22,   5410,     47,   2075,\n",
      "          47822,     24,   5410,  34433,   1242,  15159,     72,     28,     15,\n",
      "             92,  47822,     20,     15,     92,    264,  62686,  47822,     72,\n",
      "          31716,  16448,  12209,  57960,   1242,  15159,     72,     28,     15,\n",
      "             92,  47822,     20,     15,     92,    760,     64,   5318,     91,\n",
      "          34433,     67,  37018,     90,     76,  15170,     77,  31716,   1154,\n",
      "           1380,    400,     76,      3,    323,    400,     77,      3,    525,\n",
      "          12040,  10250,   6785,  25780,     13,   7379,    400,     76,  38334,\n",
      "              3,    659]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'label': tensor([0, 5, 1, 0])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b75dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
